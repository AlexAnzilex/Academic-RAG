# ğŸ“š Academic RAG System

A Retrieval-Augmented Generation (RAG) system for querying academic PDFs using local AI models. Built with LangChain, ChromaDB, and Ollama

## âœ¨ Features

- ğŸ” **Semantic Search** - Find relevant information across multiple PDFs
- ğŸ¤– **Local AI** - Uses Ollama (no API costs, complete privacy)
- âš¡ **Fast Retrieval** - ChromaDB vector database for efficient similarity search
- ğŸ¨ **Multiple Interfaces** - CLI, REST API, and Web UI
- ğŸ“Š **Source Attribution** - Shows which PDF and page the answer comes from
- ğŸ”„ **Persistent Storage** - Vector database saved on disk

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF Files â”‚â”€â”€â”€â”€â–¶â”‚  Ingest.py   â”‚â”€â”€â”€â”€â–¶â”‚  ChromaDB   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ (Embedding)  â”‚     â”‚ (Vectors)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                    â”‚   Query      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚   + Ollama   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
   â”‚   CLI   â”‚      â”‚  REST API  â”‚    â”‚   Web UI   â”‚
   â”‚ (rag.py)â”‚      â”‚  (api.py)  â”‚    â”‚  (app.py)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- [Ollama](https://ollama.com/download) installed and running

### Installation

1. **Clone repository**
```bash
git clone https://github.com/yourusername/Academic-RAG.git
cd Academic-RAG.git
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Install and start Ollama**
```bash
# Install Ollama (if not already installed)
curl -fsSL https://ollama.com/install.sh | sh

# Download model
ollama pull llama3.1:8b

# Start Ollama (usually automatic)
ollama serve
```

5. **Add your PDFs**
```bash
# Place your PDF files in data/pdf/
mkdir -p data/pdf
cp your_papers.pdf data/pdf/
```

6. **Create vector database**
```bash
python src/ingest.py
```

### Usage

#### Option 1: CLI (Interactive Chat)
```bash
python src/rag.py
```

#### Option 2: REST API
```bash
# Start server
uvicorn src.api:app --reload --host 0.0.0.0 --port 8000

# Test with curl
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "How does attention mechanism work?"}'

# Or visit interactive docs
open http://localhost:8000/docs
```

#### Option 3: Web UI (Streamlit)
```bash
streamlit run src/app.py
```

## ğŸ“ Project Structure

```
academic-rag/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pdf/                    # Your PDF files go here
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ingest.py              # PDF ingestion and embedding
â”‚   â”œâ”€â”€ rag.py                 # RAG query engine (CLI)
â”‚   â”œâ”€â”€ api.py                 # FastAPI REST API
â”‚   â””â”€â”€ app.py                 # Streamlit web interface
â”œâ”€â”€ chroma_db/                 # Vector database (created by ingest.py)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Changing Models

Edit model in `src/rag.py`, `src/api.py`, or `src/app.py`:

```python
rag = AcademicRAG(
    model="llama3.1:8b",  # Options: llama3.1:8b, mistral:7b, phi3:mini
    top_k=5               # Number of chunks to retrieve
)
```

### Chunk Size

Adjust chunking parameters in `src/ingest.py`:

```python
ingestor = PDFIngestor(
    chunk_size=1000,      # Characters per chunk
    chunk_overlap=200     # Overlap between chunks
)
```

## ğŸ“Š API Endpoints

### `POST /query`
Query the RAG system

**Request:**
```json
{
  "question": "How does attention mechanism work?",
  "top_k": 5
}
```

**Response:**
```json
{
  "answer": "The attention mechanism is...",
  "sources": ["attention.pdf", "transformer.pdf"],
  "contexts_count": 5,
  "processing_time": 2.3
}
```

### `GET /health`
Check system health

**Response:**
```json
{
  "status": "healthy",
  "ollama_connected": true,
  "vectordb_loaded": true,
  "chunks_count": 152
}
```

### `GET /stats`
Database statistics

**Response:**
```json
{
  "total_chunks": 152,
  "total_pdfs": 4,
  "model": "llama3.1:8b",
  "collection_name": "academic_papers"
}
```

## ğŸ¯ Use Cases

- ğŸ“– **Research** - Query multiple papers simultaneously
- ğŸ“ **Study Aid** - Quick answers from textbooks and lecture notes
- ğŸ“ **Literature Review** - Find relevant information across papers
- ğŸ”¬ **Lab Notes** - Search through experimental documentation

## ğŸ› ï¸ Tech Stack

- **LangChain** - RAG orchestration framework
- **ChromaDB** - Vector database for embeddings
- **Ollama** - Local LLM inference
- **HuggingFace** - Sentence transformers for embeddings
- **FastAPI** - REST API framework
- **Streamlit** - Web UI framework
- **PyPDF** - PDF text extraction

## ğŸš§ Roadmap

- [ ] Support for multiple languages
- [ ] Add document filters (by date, author, etc.)
- [ ] Implement conversation memory
- [ ] Add citation extraction
- [ ] Support for images and tables
- [ ] Export chat history
- [ ] Docker deployment

## ğŸ“ License

MIT License - feel free to use for your projects!

## ğŸ¤ Contributing

Contributions welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Contact

Alex Anzile - [@alexanzilex](www.linkedin.com/in/alexanzile)

Project Link: [https://github.com/yourusername/Academic-RAG](https://github.com/yourusername/Academic-RAG)

## ğŸ™ Acknowledgments

- [LangChain](https://langchain.com/) for RAG framework
- [Ollama](https://ollama.com/) for local LLM inference
- [ChromaDB](https://www.trychroma.com/) for vector database


---

â­ If you find this project useful, please consider giving it a star!
